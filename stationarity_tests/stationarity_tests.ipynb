{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os, sys\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../src/')))\n",
    "from networks import *\n",
    "from generative_models import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "network = HeteroscedasticNetwork(6, 6)\n",
    "network.load_weights('../model_comparison/checkpoints/varying_hyperparams_3200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv('../data/data_lexical_decision.csv', sep=',', header=0)\n",
    "data.loc[data.acc == 0, 'rt'] = -data.loc[data.acc == 0, 'rt']\n",
    "data.loc[:, 'stim_type'] = data.loc[:, 'stim_type'] - 1\n",
    "emp_data = data[['rt', 'stim_type']].to_numpy().reshape(11, 3200, 2)\n",
    "emp_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amortized inference\n",
    "net_in = tf.concat((emp_data[:, :, :1], to_categorical(emp_data[:, :, 1:])), axis=-1)\n",
    "post_d, post_s = network(net_in)\n",
    "post_d.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(post_d.mean()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpss_test(timeseries):\n",
    "    print(\"Results of KPSS Test:\")\n",
    "    kpsstest = kpss(timeseries, regression=\"c\", nlags=\"auto\")\n",
    "    kpss_output = pd.Series(\n",
    "        kpsstest[0:3], index=[\"Test Statistic\", \"p-value\", \"Lags Used\"]\n",
    "    )\n",
    "    for key, value in kpsstest[3].items():\n",
    "        kpss_output[\"Critical Value (%s)\" % key] = value\n",
    "    print(kpss_output)\n",
    "\n",
    "def adf_test(timeseries):\n",
    "    print(\"Results of Dickey-Fuller Test:\")\n",
    "    dftest = adfuller(timeseries, autolag=\"AIC\")\n",
    "    dfoutput = pd.Series(\n",
    "        dftest[0:4],\n",
    "        index=[\n",
    "            \"Test Statistic\",\n",
    "            \"p-value\",\n",
    "            \"#Lags Used\",\n",
    "            \"Number of Observations Used\",\n",
    "        ],\n",
    "    )\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput[\"Critical Value (%s)\" % key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of KPSS Test:\n",
      "Test Statistic            6.23086\n",
      "p-value                   0.01000\n",
      "Lags Used                25.00000\n",
      "Critical Value (10%)      0.34700\n",
      "Critical Value (5%)       0.46300\n",
      "Critical Value (2.5%)     0.57400\n",
      "Critical Value (1%)       0.73900\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cognitiveModeling/lib/python3.9/site-packages/statsmodels/tsa/stattools.py:1906: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is smaller than the p-value returned.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rt = np.abs(emp_data[0, :, 0])\n",
    "kpss_test(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Dickey-Fuller Test:\n",
      "Test Statistic                -7.493450e+00\n",
      "p-value                        4.442852e-11\n",
      "#Lags Used                     2.100000e+01\n",
      "Number of Observations Used    3.178000e+03\n",
      "Critical Value (1%)           -3.432409e+00\n",
      "Critical Value (5%)           -2.862450e+00\n",
      "Critical Value (10%)          -2.567254e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "adf_test(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests for empiric rt time series\n",
    "n_sub = post_d.shape[0]\n",
    "adf_data = list()\n",
    "kpss_data = list()\n",
    "adf_data_p_value = np.empty(n_sub)\n",
    "kpss_data_p_value = np.empty(n_sub)\n",
    "for sub in range(n_sub):\n",
    "    # subset rt time series\n",
    "    rt = np.abs(emp_data[sub, :, 0])\n",
    "\n",
    "    # compute tests\n",
    "    adf_test = adfuller(rt)\n",
    "    kpss_test = kpss(rt, nlags=\"auto\")\n",
    "\n",
    "    # store results\n",
    "    adf_data.append(adf_test)\n",
    "    kpss_data.append(kpss_test)\n",
    "\n",
    "    # store p-values separately\n",
    "    adf_data_p_value[sub] = adf_test[1]\n",
    "    kpss_data_p_value[sub] = kpss_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.44285197e-11, 2.97087065e-14, 3.63060117e-18, 1.61012454e-07,\n",
       "       1.17180126e-19, 1.50037787e-15, 9.32761707e-09, 1.59047171e-07,\n",
       "       3.63820101e-20, 7.45553555e-07, 4.25602098e-29])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adf_data_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01      , 0.01      , 0.01      , 0.01      , 0.04811223,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      ])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpss_data_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests for dynamic parameters\n",
    "n_sub = post_d.shape[0]\n",
    "n_trim = 200\n",
    "adf_params_p_value = np.empty((n_sub, 6))\n",
    "kpss_params_p_value = np.empty((n_sub, 6))\n",
    "for sub in range(n_sub):\n",
    "    for i in range(6):\n",
    "        # compute tests\n",
    "        adf_test = adfuller(np.array(post_d.mean()[sub])[n_trim:, i])\n",
    "        kpss_test = kpss(np.array(post_d.mean()[sub])[n_trim:, i], nlags=\"auto\")\n",
    "\n",
    "        # store p-values separately\n",
    "        adf_params_p_value[sub, i] = adf_test[1]\n",
    "        kpss_params_p_value[sub, i] = kpss_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_params_p_value[which]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpss_params_p_value[which]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(np.arange(n_trim, 3200), np.array(post_d.mean()[which])[n_trim:, 5])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5c1a6784774cb00c4ca0a99fd750e2e4caf18aa135f6d49553516d8651234b4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cognitiveModeling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
