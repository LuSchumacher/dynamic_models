{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from tqdm.notebook import tqdm\n",
    "# import talib\n",
    "import pickle\n",
    "import pystan\n",
    "\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../')))\n",
    "from generative_models import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu setting and checking\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amortizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroscedasticNetwork(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, n_params_d, n_params_s):\n",
    "        super(HeteroscedasticNetwork, self).__init__()\n",
    "        \n",
    "        self.preprocessor = Sequential([\n",
    "            GRU(64, return_sequences=True),\n",
    "            LSTM(128, return_sequences=True),\n",
    "            Dense(128, activation='selu', kernel_initializer='lecun_normal'),\n",
    "        ])\n",
    "        \n",
    "        self.dynamic_predictor = Sequential([\n",
    "            Dense(64, activation='selu', kernel_initializer='lecun_normal'),\n",
    "            tf.keras.layers.Dense(tfpl.MultivariateNormalTriL.params_size(n_params_d)),\n",
    "            tfpl.MultivariateNormalTriL(n_params_d)\n",
    "        ])\n",
    "\n",
    "        self.static_predictor = Sequential([\n",
    "            LSTM(n_params_s),\n",
    "            Dense(tfpl.MultivariateNormalTriL.params_size(n_params_s)),\n",
    "            tfpl.MultivariateNormalTriL(n_params_s)\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Obtain representation\n",
    "        rep = self.preprocessor(x)\n",
    "        \n",
    "        # Predict dynamic\n",
    "        preds_dyn = self.dynamic_predictor(rep)\n",
    "\n",
    "        # predict static\n",
    "        preds_stat = self.static_predictor(rep)\n",
    "\n",
    "        return preds_dyn, preds_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(y_true, y_pred):\n",
    "    return tf.reduce_mean(-y_pred.log_prob(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_trainer(network, optimizer, batch_size, n_obs, steps_per_epoch, p_bar):\n",
    "    losses = []\n",
    "    for step in range(1, steps_per_epoch+1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Simulate from model\n",
    "            prior_draws = dynamic_prior(batch_size)\n",
    "            context = context_gen(batch_size, n_obs)\n",
    "            sim_data, theta_d, theta_s = dynamic_batch_simulator(prior_draws, context)\n",
    "\n",
    "            # predict\n",
    "            net_in = tf.concat((sim_data[:, :, :1], to_categorical(sim_data[:, :, 1:])), axis=-1)\n",
    "            pred_theta_d, pred_theta_s = network(net_in)\n",
    "\n",
    "            # loss\n",
    "            loss_d = nll(theta_d, pred_theta_d)\n",
    "            loss_s = nll(theta_s, pred_theta_s)\n",
    "            total_loss = loss_d + loss_s\n",
    "\n",
    "        g = tape.gradient(total_loss, network.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(g, network.trainable_variables))\n",
    "        losses.append(total_loss.numpy())\n",
    "\n",
    "        # Update progress bar\n",
    "        p_bar.set_postfix_str(\"Ep: {},Step {},Loss D: {:.3f} Running Loss: {:.3f}\"\n",
    "                              .format(ep, step, loss_d.numpy(), np.mean(losses)))\n",
    "        p_bar.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OBS = 800\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "STEPS_PER_EPOCH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "network = HeteroscedasticNetwork(6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(1, EPOCHS+1):\n",
    "    with tqdm(total=STEPS_PER_EPOCH, desc='Training epoch {}'.format(ep)) as p_bar:\n",
    "        epoch_trainer(network, optimizer, BATCH_SIZE, N_OBS, STEPS_PER_EPOCH, p_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.save_weights('checkpoints/varying_hyperparams_800')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5c1a6784774cb00c4ca0a99fd750e2e4caf18aa135f6d49553516d8651234b4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cognitiveModeling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
